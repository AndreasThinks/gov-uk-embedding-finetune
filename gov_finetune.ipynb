{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "63150eba",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "%load_ext autoreload\n",
        "\n",
        "\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "551753b7-6cd2-4f81-aec0-da119e4705ad",
      "metadata": {
        "id": "551753b7-6cd2-4f81-aec0-da119e4705ad"
      },
      "source": [
        "# Finetune Embeddings\n",
        "\n",
        "In this notebook, we show users how to finetune their own embedding models.\n",
        "\n",
        "We go through three main sections:\n",
        "1. Preparing the data (our `generate_qa_embedding_pairs` function makes this easy)\n",
        "2. Finetuning the model (using our `SentenceTransformersFinetuneEngine`)\n",
        "3. Evaluating the model on a validation knowledge corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99afd542-fc47-44ac-aed0-b3684108dba5",
      "metadata": {
        "id": "99afd542-fc47-44ac-aed0-b3684108dba5"
      },
      "source": [
        "## Generate Corpus\n",
        "\n",
        "First, we create the corpus of text chunks by leveraging LlamaIndex to load some financial PDFs, and parsing/chunking into plain text chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9280d438-b6bd-4ccf-a730-7c8bb3ebdbeb",
      "metadata": {
        "id": "9280d438-b6bd-4ccf-a730-7c8bb3ebdbeb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.schema import MetadataMode"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c42620",
      "metadata": {
        "id": "73c42620"
      },
      "source": [
        "Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d8e11b0c",
      "metadata": {
        "id": "d8e11b0c"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
        "\n",
        "\n",
        "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
        "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "55402b72",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'from llama_index.finetuning import SentenceTransformersFinetuneEngine\\n\\nfinetune_engine = SentenceTransformersFinetuneEngine(\\n    train_dataset,\\n    model_id=\"Alibaba-NLP/gte-large-en-v1.5\",\\n    model_output_path=\"gte-large-en-v1.5-ukgov-finetuned\",\\n    val_dataset=val_dataset,\\n    trust_remote_code=True\\n)'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
        "\n",
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    train_dataset,\n",
        "    model_id=\"Alibaba-NLP/gte-large-en-v1.5\",\n",
        "    model_output_path=\"gte-large-en-v1.5-ukgov-finetuned\",\n",
        "    val_dataset=val_dataset,\n",
        "    trust_remote_code=True\n",
        ")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "03f7353f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'from llama_index.finetuning import SentenceTransformersFinetuneEngine\\n\\nfinetune_engine = SentenceTransformersFinetuneEngine(\\n    train_dataset,\\n    model_id=\"sentence-transformers/all-mpnet-base-v2-2\",\\n    model_output_path=\"all-mpnet-base-v2-ukgov-finetuned\",\\n    val_dataset=val_dataset,\\n    trust_remote_code=True\\n)\\n\\nfinetune_engine.finetune()\\n\\nembed_model = finetune_engine.get_finetuned_model()\\nembed_model\\n'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
        "\n",
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    train_dataset,\n",
        "    model_id=\"sentence-transformers/all-mpnet-base-v2-2\",\n",
        "    model_output_path=\"all-mpnet-base-v2-ukgov-finetuned\",\n",
        "    val_dataset=val_dataset,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "finetune_engine.finetune()\n",
        "\n",
        "embed_model = finetune_engine.get_finetuned_model()\n",
        "embed_model\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9786632d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "57f3f86f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8df427a7d41477e9e006e840efd21ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\andre\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-mpnet-base-dot-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c766cf50665142e08ca01236c6c47a84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e8e321289084faeab286daa68e761b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5c134af87034aac9cdad1cca7026333",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3967e37b02b14c0fb6178a5023993794",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd5175fd26ac429d8b2e32c020e8f260",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3ca1e934f704e45ade670fddc88ce90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "773a82fe56e04d1faad54593133621fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62559e3320774e79989044a5df23973a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "490f665709de46568ca4e0f468a688d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaab1df80af0475e8f4a5efecfa7bdec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "568168aec61f49fdbd61b185ceb01402",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dedc0757e154e35ad763af4662d7b22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/5114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformersFinetuneEngine\n\u001b[0;32m      3\u001b[0m finetune_engine \u001b[38;5;241m=\u001b[39m SentenceTransformersFinetuneEngine(\n\u001b[0;32m      4\u001b[0m     train_dataset,\n\u001b[0;32m      5\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/multi-qa-mpnet-base-dot-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m \u001b[43mfinetune_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m finetune_engine\u001b[38;5;241m.\u001b[39mget_finetuned_model()\n\u001b[0;32m     14\u001b[0m embed_model\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\llama_index\\finetuning\\embeddings\\sentence_transformer.py:79\u001b[0m, in \u001b[0;36mSentenceTransformersFinetuneEngine.finetune\u001b[1;34m(self, **train_kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinetune\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrain_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finetune model.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_output_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1098\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[0;32m   1096\u001b[0m     skip_scheduler \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mget_scale() \u001b[38;5;241m!=\u001b[39m scale_before_step\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1098\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mloss_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m     loss_value\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   1100\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(loss_model\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\sentence_transformers\\losses\\MultipleNegativesRankingLoss.py:85\u001b[0m, in \u001b[0;36mMultipleNegativesRankingLoss.forward\u001b[1;34m(self, sentence_features, labels)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence_features: Iterable[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]], labels: Tensor):\n\u001b[1;32m---> 85\u001b[0m     reps \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence_embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     86\u001b[0m     embeddings_a \u001b[38;5;241m=\u001b[39m reps[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     87\u001b[0m     embeddings_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(reps[\u001b[38;5;241m1\u001b[39m:])\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\sentence_transformers\\losses\\MultipleNegativesRankingLoss.py:85\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence_features: Iterable[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]], labels: Tensor):\n\u001b[1;32m---> 85\u001b[0m     reps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sentence_feature \u001b[38;5;129;01min\u001b[39;00m sentence_features]\n\u001b[0;32m     86\u001b[0m     embeddings_a \u001b[38;5;241m=\u001b[39m reps[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     87\u001b[0m     embeddings_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(reps[\u001b[38;5;241m1\u001b[39m:])\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:545\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    544\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[1;32m--> 545\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    553\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    554\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:335\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    333\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m--> 335\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:294\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    287\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    293\u001b[0m ):\n\u001b[1;32m--> 294\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    302\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:235\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    228\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    234\u001b[0m ):\n\u001b[1;32m--> 235\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(self_outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m hidden_states)\n\u001b[0;32m    243\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:182\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1885\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1883\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1885\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
        "\n",
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    train_dataset,\n",
        "    model_id=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n",
        "    model_output_path=\"multi-qa-mpnet-base-dot-v1-ukgov-finetuned\",\n",
        "    val_dataset=val_dataset,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "finetune_engine.finetune()\n",
        "\n",
        "embed_model = finetune_engine.get_finetuned_model()\n",
        "embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "733ff558",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andre\\OneDrive\\Documents\\projects\\policy-embedding\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.3.0+cu121 with CUDA 1201 (you have 2.3.1+cpu)\n",
            "    Python  3.11.9 (you have 3.11.9)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15fd58298853442190906acbdc559b8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14ffa21f5edc4f6092eb2eb1498235ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/5114 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "'''from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
        "\n",
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    train_dataset,\n",
        "    model_id=\"Alibaba-NLP/gte-large-en-v1.5\",\n",
        "    model_output_path=\"gte-large-en-v1.5-ukgov-finetuned\",\n",
        "    val_dataset=val_dataset,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "finetune_engine.finetune()\n",
        "\n",
        "embed_model = finetune_engine.get_finetuned_model()\n",
        "embed_model'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "828dd6fe-9a8a-419b-8663-56d81ce73774",
      "metadata": {
        "id": "828dd6fe-9a8a-419b-8663-56d81ce73774"
      },
      "source": [
        "## Evaluate Finetuned Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b703ec41",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f4a66b83-4cbb-4374-a632-0f1bb2b785ab",
      "metadata": {
        "id": "f4a66b83-4cbb-4374-a632-0f1bb2b785ab"
      },
      "source": [
        "In this section, we evaluate 3 different embedding models:\n",
        "1. proprietary OpenAI embedding,\n",
        "2. open source `BAAI/bge-small-en`, and\n",
        "3. our finetuned embedding model.\n",
        "\n",
        "We consider 2 evaluation approaches:\n",
        "1. a simple custom **hit rate** metric\n",
        "2. using `InformationRetrievalEvaluator` from sentence_transformers\n",
        "\n",
        "We show that finetuning on synthetic (LLM-generated) dataset significantly improve upon an opensource embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d5176f-1f21-4bcb-adf5-da1c4cccb8d3",
      "metadata": {
        "id": "57d5176f-1f21-4bcb-adf5-da1c4cccb8d3"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.schema import TextNode\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dda4c2b8-1ad8-420c-83d2-b88e0519895d",
      "metadata": {
        "id": "dda4c2b8-1ad8-420c-83d2-b88e0519895d"
      },
      "source": [
        "### Define eval function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "398c24d3-3d72-4ce8-94a4-2da9c1b2605c",
      "metadata": {
        "id": "398c24d3-3d72-4ce8-94a4-2da9c1b2605c"
      },
      "source": [
        "**Option 1**: We use a simple **hit rate** metric for evaluation:\n",
        "* for each (query, relevant_doc) pair,\n",
        "* we retrieve top-k documents with the query,  and\n",
        "* it's a **hit** if the results contain the relevant_doc.\n",
        "\n",
        "This approach is very simple and intuitive, and we can apply it to both the proprietary OpenAI embedding as well as our open source and fine-tuned embedding models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89401d3-a157-4f96-86d4-212e631a54bc",
      "metadata": {
        "id": "b89401d3-a157-4f96-86d4-212e631a54bc"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def evaluate(\n",
        "    dataset,\n",
        "    embed_model,\n",
        "    top_k=5,\n",
        "    verbose=False,\n",
        "):\n",
        "    corpus = dataset.corpus\n",
        "    queries = dataset.queries\n",
        "    relevant_docs = dataset.relevant_docs\n",
        "\n",
        "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
        "    index = VectorStoreIndex(\n",
        "        nodes, embed_model=embed_model, show_progress=True\n",
        "    )\n",
        "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
        "\n",
        "    eval_results = []\n",
        "    for query_id, query in tqdm(queries.items()):\n",
        "        retrieved_nodes = retriever.retrieve(query)\n",
        "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
        "        expected_id = relevant_docs[query_id][0]\n",
        "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
        "\n",
        "        eval_result = {\n",
        "            \"is_hit\": is_hit,\n",
        "            \"retrieved\": retrieved_ids,\n",
        "            \"expected\": expected_id,\n",
        "            \"query\": query_id,\n",
        "        }\n",
        "        eval_results.append(eval_result)\n",
        "    return eval_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb16251-bb45-4de0-b65a-e15aa76e0f1e",
      "metadata": {
        "id": "7eb16251-bb45-4de0-b65a-e15aa76e0f1e"
      },
      "source": [
        "**Option 2**: We use the `InformationRetrievalEvaluator` from sentence_transformers.\n",
        "\n",
        "This provides a more comprehensive suite of metrics, but we can only run it against the sentencetransformers compatible models (open source and our finetuned model, *not* the OpenAI embedding model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e89702-ea35-4c22-99c7-f89a5428ef95",
      "metadata": {
        "id": "88e89702-ea35-4c22-99c7-f89a5428ef95"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def evaluate_st(\n",
        "    dataset,\n",
        "    model_id,\n",
        "    name,\n",
        "):\n",
        "    corpus = dataset.corpus\n",
        "    queries = dataset.queries\n",
        "    relevant_docs = dataset.relevant_docs\n",
        "\n",
        "    evaluator = InformationRetrievalEvaluator(\n",
        "        queries, corpus, relevant_docs, name=name\n",
        "    )\n",
        "    model = SentenceTransformer(model_id)\n",
        "    output_path = \"results/\"\n",
        "    Path(output_path).mkdir(exist_ok=True, parents=True)\n",
        "    return evaluator(model, output_path=output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2d33dd-c39f-4c05-8adc-65db12163c88",
      "metadata": {
        "id": "af2d33dd-c39f-4c05-8adc-65db12163c88"
      },
      "source": [
        "### Run Evals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c630aa25-2395-4a8b-83cf-2885fbc862f4",
      "metadata": {
        "id": "c630aa25-2395-4a8b-83cf-2885fbc862f4"
      },
      "source": [
        "#### OpenAI\n",
        "\n",
        "Note: this might take a few minutes to run since we have to embed the corpus and queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3e927b",
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# use python dotenv to read the API key\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "openai_api_key = os.getenv(\"OPEN_AI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a0784f-415e-4d3a-8c88-757b28b9e5df",
      "metadata": {
        "id": "61a0784f-415e-4d3a-8c88-757b28b9e5df"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "ada = OpenAIEmbedding(api_key=openai_api_key)\n",
        "ada_val_results = evaluate(val_dataset, ada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc73212-fc53-48c1-b347-f5ee3a29ae82",
      "metadata": {
        "id": "ccc73212-fc53-48c1-b347-f5ee3a29ae82"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df_ada = pd.DataFrame(ada_val_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25eb61bb-c287-40fe-b3c7-bbfc2d2b1b94",
      "metadata": {
        "id": "25eb61bb-c287-40fe-b3c7-bbfc2d2b1b94",
        "outputId": "a3b1b5f7-4a72-4ab1-a5f2-c74afd56b5dd"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "hit_rate_ada = df_ada[\"is_hit\"].mean()\n",
        "hit_rate_ada"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1bd6c62-65a8-4f72-a67c-d0d62c92d7d1",
      "metadata": {
        "id": "a1bd6c62-65a8-4f72-a67c-d0d62c92d7d1"
      },
      "source": [
        "### BAAI/bge-small-en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24454aeb-9e3e-4954-ab70-647102ed7f82",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6e9c5f0555f641caa3a5a5d11cb87583",
            "1fe9a221f8984c818727771d12dfef71",
            "619c9cae8bf24987a4d3453aa69d24b9",
            "082cfe7c9f3646948886c90f0e1f4258",
            "3ff8d7a739fc425abf24076c47c0ab29",
            "0a5344851cb14ed8a5f788cbd74a90d8",
            "eaa8bdab99244058b1df3eae12a79b20",
            "e21b1a35d6c54644be124c357852fedf",
            "927efec699ea4c929da7214eb51fc64c",
            "1c8a00d15090422181a9749e0638e883",
            "3845bc276c88482ba0e2f2fbe317dd78",
            "7ceca7b6507e42b1b3da10711b37b7ab",
            "21170e7cf0f9485a9095807a6225aa12",
            "3712232b7e064486879945c4d4ac5535",
            "ba1f47ec020447c59d008493b31e0a57"
          ]
        },
        "id": "24454aeb-9e3e-4954-ab70-647102ed7f82",
        "outputId": "eefe1e67-e98a-4d11-b1e2-0a665af7a04f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "bge = \"local:BAAI/bge-small-en\"\n",
        "bge_val_results = evaluate(val_dataset, bge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da27e48-1c90-4994-aac4-96b5b1638647",
      "metadata": {
        "id": "2da27e48-1c90-4994-aac4-96b5b1638647"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df_bge = pd.DataFrame(bge_val_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddc4fe0-b240-4c15-9b2d-a4c79f9aaac2",
      "metadata": {
        "id": "3ddc4fe0-b240-4c15-9b2d-a4c79f9aaac2",
        "outputId": "c7656245-6fe2-447e-a16a-b09f890e7570"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "hit_rate_bge = df_bge[\"is_hit\"].mean()\n",
        "hit_rate_bge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c16df14-6564-41ec-8816-348675bb0fd4",
      "metadata": {
        "id": "2c16df14-6564-41ec-8816-348675bb0fd4",
        "outputId": "f07e4e0e-c357-40b8-eecd-849a32e3a931"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "evaluate_st(val_dataset, \"BAAI/bge-small-en\", name=\"bge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd87550-f547-4b8b-b21a-f72b355e2cd7",
      "metadata": {
        "id": "1fd87550-f547-4b8b-b21a-f72b355e2cd7"
      },
      "source": [
        "### Finetuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "402dd440-1934-4778-8ff5-28e15cf1f2d3",
      "metadata": {
        "id": "402dd440-1934-4778-8ff5-28e15cf1f2d3"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "finetuned = \"local:test_model\"\n",
        "val_results_finetuned = evaluate(val_dataset, finetuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffd24643-17cb-4773-a535-77f3f8fa2d48",
      "metadata": {
        "id": "ffd24643-17cb-4773-a535-77f3f8fa2d48"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df_finetuned = pd.DataFrame(val_results_finetuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1dccd1-bbd4-427f-a520-b1011643d83b",
      "metadata": {
        "id": "ec1dccd1-bbd4-427f-a520-b1011643d83b"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "hit_rate_finetuned = df_finetuned[\"is_hit\"].mean()\n",
        "hit_rate_finetuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8dd38e-f13d-43e1-9802-cc94b854526b",
      "metadata": {
        "id": "9d8dd38e-f13d-43e1-9802-cc94b854526b"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "evaluate_st(val_dataset, \"test_model\", name=\"finetuned\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc290bc-5cc3-4ee4-b8ab-e68371441643",
      "metadata": {
        "id": "fbc290bc-5cc3-4ee4-b8ab-e68371441643"
      },
      "source": [
        "### Summary of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f906a11-6a95-4f10-9069-140bf5a56246",
      "metadata": {
        "id": "6f906a11-6a95-4f10-9069-140bf5a56246"
      },
      "source": [
        "#### Hit rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705fbe3c-2843-4bab-bb5c-16027fc5564b",
      "metadata": {
        "id": "705fbe3c-2843-4bab-bb5c-16027fc5564b"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df_ada[\"model\"] = \"ada\"\n",
        "df_bge[\"model\"] = \"bge\"\n",
        "df_finetuned[\"model\"] = \"fine_tuned\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebc363c-cd07-4dab-916e-1618d16d1254",
      "metadata": {
        "id": "bebc363c-cd07-4dab-916e-1618d16d1254"
      },
      "source": [
        "We can see that fine-tuning our small open-source embedding model drastically improve its retrieval quality (even approaching the quality of the proprietary OpenAI embedding)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f38b4b-1b40-42da-a054-ea9593d3e602",
      "metadata": {
        "id": "57f38b4b-1b40-42da-a054-ea9593d3e602"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df_all = pd.concat([df_ada, df_bge, df_finetuned])\n",
        "df_all.groupby(\"model\").mean(\"is_hit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08094d07-2c0a-44ca-ad2f-8d8bf1387ed9",
      "metadata": {
        "id": "08094d07-2c0a-44ca-ad2f-8d8bf1387ed9"
      },
      "source": [
        "#### InformationRetrievalEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d0444e-a824-42d6-9ddb-4da7179902bc",
      "metadata": {
        "id": "27d0444e-a824-42d6-9ddb-4da7179902bc"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df_st_bge = pd.read_csv(\n",
        "    \"results/Information-Retrieval_evaluation_bge_results.csv\"\n",
        ")\n",
        "df_st_finetuned = pd.read_csv(\n",
        "    \"results/Information-Retrieval_evaluation_finetuned_results.csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0903ed3-df05-4d98-8b0a-6f352c681735",
      "metadata": {
        "id": "c0903ed3-df05-4d98-8b0a-6f352c681735"
      },
      "source": [
        "We can see that embedding finetuning improves metrics consistently across the suite of eval metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ec1c46-5aa0-4f8a-a0c5-2553e08cceb1",
      "metadata": {
        "id": "81ec1c46-5aa0-4f8a-a0c5-2553e08cceb1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/andre/OneDrive/Documents/projects/policy-embedding/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "df_st_bge[\"model\"] = \"bge\"\n",
        "df_st_finetuned[\"model\"] = \"fine_tuned\"\n",
        "df_st_all = pd.concat([df_st_bge, df_st_finetuned])\n",
        "df_st_all = df_st_all.set_index(\"model\")\n",
        "df_st_all"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
